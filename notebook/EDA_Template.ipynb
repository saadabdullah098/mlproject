{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7672c1d2",
   "metadata": {},
   "source": [
    "# Project Title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad0cd28",
   "metadata": {},
   "source": [
    "## Project Breakdown and Dataset Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9860fc73",
   "metadata": {},
   "source": [
    "### Life Cycle of Project\n",
    "\n",
    "- Understanding the Problem Statement\n",
    "- Data Collection\n",
    "- Data Checks to perform\n",
    "- Exploratory data analysis\n",
    "- Data Pre-Processing\n",
    "- Model Training\n",
    "- Choose best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d788dc2",
   "metadata": {},
   "source": [
    "### 1) Problem statement\n",
    "- This project understands how the student's performance (test scores) is affected by other variables such as Gender, Ethnicity, Parental level of education, Lunch and Test preparation course.\n",
    "\n",
    "\n",
    "### 2) Data Collection\n",
    "- Dataset Source - https://www.kaggle.com/datasets/spscientist/students-performance-in-exams?datasetId=74977\n",
    "- The data consists of 8 column and 1000 rows.\n",
    "\n",
    "#### 2.1) Dataset Information\n",
    "- gender : sex of students  -> (Male/female)\n",
    "- race/ethnicity : ethnicity of students -> (Group A, B,C, D,E)\n",
    "- parental level of education : parents' final education ->(bachelor's degree,some college,master's degree,associate's degree,high school)\n",
    "- lunch : having lunch before test (standard or free/reduced) \n",
    "- test preparation course : complete or not complete before test\n",
    "- math score\n",
    "- reading score\n",
    "- writing score\n",
    "\n",
    "#### 2.2) Import Data and Required Packages\n",
    "- Importing Pandas, Numpy, Matplotlib, Seaborn and Warings Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d49fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f59aa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data from CSV or write code to import from database\n",
    "df = pd.read_csv('data/stud.csv')\n",
    "#Shape of dataset\n",
    "print(df.shape)\n",
    "#Show first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1ab1f4",
   "metadata": {},
   "source": [
    "### 3) Data Checks to perform\n",
    "\n",
    "- Check Missing values\n",
    "- Check Duplicates\n",
    "- Check Data Types\n",
    "- Check the number of unique values of each column\n",
    "- Check statistics of data set\n",
    "- Check various categories present in the different categorical column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2de08f",
   "metadata": {},
   "source": [
    "#### 3.1) Check Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ccf428",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-37dcbced512b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### 3.1 Check Missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b64b7c",
   "metadata": {},
   "source": [
    "##### Oberservation and Handling Missing Values\n",
    "Options for imputation from sklearn include:\n",
    "- SimpleImputer() with Mean, Median, Mode, or Constant values\n",
    "- KNNImputer() that uses the avergage of the k-nearest neighbors (can adjust weights of neighbors)\n",
    "- MissingIndicator() that creates binary indicators for missing values by adding a new column containing 0s and 1s. This can improve performance by allowing the model to learn patterns in the missingness itself.\n",
    "- IterativeImputer starts by filling missing values with something simple (like the mean). Then iterates:\n",
    "    - Pick a feature (column) with missing values.\n",
    "    - Treat this column as the target y, and the other columns as predictors X.\n",
    "    - Train a regression model (like BayesianRidge or DecisionTreeRegressor) on the known values.\n",
    "    - Predict the missing values for this column.\n",
    "    - Repeat this for each feature with missing values.\n",
    "\n",
    "    Repeat the above process for multiple rounds to refine the imputations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64315268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling Missing Values\n",
    "#Remove values or Imputation: Mean/Mode, Regression, or Imputation with Perturbation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdea574",
   "metadata": {},
   "source": [
    "#### 3.2) Check Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09955b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a22ff4",
   "metadata": {},
   "source": [
    "##### Oberservation and Deleting Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c32b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling Duplicate Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a844b852",
   "metadata": {},
   "source": [
    "#### Encoders\n",
    "\n",
    "One-Hot Encoders Converts categories into binary (0/1) columns. Each unique category becomes a separate column. A 1 is placed in the column that represents the actual category, and 0s elsewhere. Use when: Categories have no inherent order (e.g., colors, country names, brands). You're using models that assume numerical distance has meaning (like linear regression)\n",
    "\n",
    "OrdinalEncoder Converts categories into integer labels. Each category is mapped to a unique integer based on its order or appearance (small = 0, medium = 1, large = 2). Use when: Categories have a natural order (e.g., education level, shirt sizes, ratings). You’re using tree-based models that don’t assume linear relationships (e.g., decision trees, random forest, XGBoost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c2e34a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
